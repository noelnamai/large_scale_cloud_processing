## Problem 1: Getting started with Pig on chunk-000

Modify example.pig to use the file uw-cse-344-oregon.aws.amazon.com/btc-2010-chunk-000 instead of uw-cse-344-oregon.aws.amazon.com/cse344-test-file. Run on an AWS cluster with 10 small nodes. (also see hints below).

1.1 How many MapReduce jobs are generated by example.pig?

1.2 How many reduce tasks are within the first MapReduce job? How many reduce tasks are within later MapReduce jobs?

1.3 How long does each job take? How long does the entire script take?

1.4 What is the schema of the tuples after each of the following commands in example.pig?

* After the command ntriples = ...
* After the command objects = ...
* After the command count_by_object = ...

Hint 1: Use the [job tracker](https://class.coursera.org/datasci-002/wiki/view?page=awssetup) to see the number of map and reduce tasks for your MapReduce jobs.

Hint 2: To see the schema for intermediate results, you can use Pig's interactive command line client grunt, which you can launch by running Pig without specifying an input script on the command line. When using grunt, a command that you may want to know about is describe . To see a list of other commands, type help.

What you need to turn in:
How many records are there in count_by_object? DON'T FORGET TO SHUTDOWN YOUR INSTANCES!
